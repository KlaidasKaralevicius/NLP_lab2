{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KlaidasKaralevicius/NLP_lab2/blob/main/lab2_Klaidas_Karalevicius.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "yBeTEicQERaE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MJ3hHF_xAki1"
      },
      "outputs": [],
      "source": [
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from google.colab import files\n",
        "import keras\n",
        "!pip install markovify -q\n",
        "import markovify\n",
        "!pip install num2words -q\n",
        "from num2words import num2words\n",
        "!pip install pronouncing -q\n",
        "import pronouncing\n",
        "\n",
        "keras.backend.clear_session()\n",
        "keras.utils.set_random_seed(226)\n",
        "random.seed(226)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Įkelti dainų tekstus\n",
        "\n",
        "Pakeitimas nr.1, įkeliami savo duomenys susidarantys iš apie 70 dainų ir 124676 simbolių."
      ],
      "metadata": {
        "id": "zRWmGfrbEcuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://raw.githubusercontent.com/KlaidasKaralevicius/NLP_lab2/refs/heads/main/Arknights.txt\n",
        "\n",
        "artist_file = 'Arknights.txt'\n",
        "with open(artist_file, 'r') as f:\n",
        "  lyrics = f.read()"
      ],
      "metadata": {
        "id": "n3mtOr4ZEcct",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Duomenų normalizavimas"
      ],
      "metadata": {
        "id": "xSNDoXHAdYej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizuojant duomenis papildomai išfiltruojami elementai tarp \"[ ]\" kartu su šiais skliausteliais. Išfiltruojami tokie elementai kaip: [x2], [Chorus], [Verse], [Pre-chorus]..."
      ],
      "metadata": {
        "id": "IU6z3y9eIlCg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zt9z0Kyc_8X4"
      },
      "outputs": [],
      "source": [
        "def normalize_word_line(line: str) -> list[str]:\n",
        "  line = re.sub(r\"\\[.*?\\]\", \"\", line)\n",
        "  row = [x.lower() for x in re.findall(r\"\\w+'?\\w*\", line)]\n",
        "  new_row = []\n",
        "  for word in row:\n",
        "    numbers = re.findall(r\"\\d+\", word)\n",
        "    for n in numbers:\n",
        "      word = word.replace(n, num2words(int(n)))\n",
        "    new_row.append(word)\n",
        "  return new_row"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Duomenų apdorojimas (word-embedding)\n",
        "\n"
      ],
      "metadata": {
        "id": "dtKajMqyUifW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sPXH5l_nUx7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Markovo grandinės"
      ],
      "metadata": {
        "id": "hLmVEkg2kkk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "markov_model = markovify.NewlineText(lyrics)"
      ],
      "metadata": {
        "id": "bIv3dbP3kksP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n27GIbe598c3"
      },
      "source": [
        "# 4. Ritmo ištraukimas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pGA101F393i1"
      },
      "outputs": [],
      "source": [
        "def n_syllables(word_line: list[str]):\n",
        "    vowels = 'aeiouy'\n",
        "    syllable_count = 0\n",
        "\n",
        "    for word in word_line:\n",
        "        for i, char in enumerate(word):\n",
        "            if char in vowels:\n",
        "                if (i == 0) or (word[i-1] not in vowels):\n",
        "                    syllable_count += 1\n",
        "        word_vowels_count = sum([x in vowels for x in word])\n",
        "        if word_vowels_count == 0:\n",
        "            syllable_count = len(word)\n",
        "        elif word_vowels_count > 1 and (word[-1] == 'e') and (word[-2] not in vowels):\n",
        "            syllable_count -= 1\n",
        "\n",
        "    return syllable_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_fwmgC_oSexs"
      },
      "outputs": [],
      "source": [
        "def get_rhyme(line: list[str]) -> str:\n",
        "    last_word = re.sub('\\W+', '', line[-1])\n",
        "    all_rhymes = pronouncing.rhymes(last_word)\n",
        "    if all_rhymes:\n",
        "        rhyming_ends = [x[-2:] for x in all_rhymes]\n",
        "        most_common_rhyme = max(set(rhyming_ends), key = rhyming_ends.count)\n",
        "    else:\n",
        "        most_common_rhyme = last_word[-2:]\n",
        "    return most_common_rhyme\n",
        "\n",
        "\n",
        "def get_rhyme_list(normalized_lyrics: list[list[str]]):\n",
        "  rhyme_set = set()\n",
        "  for row in normalized_lyrics:\n",
        "    most_common_rhyme = get_rhyme(row)\n",
        "    rhyme_set.add(most_common_rhyme)\n",
        "\n",
        "  sorted_rhyme_set = sorted(list(rhyme_set), key = lambda x: x[-1])\n",
        "  return sorted_rhyme_set\n",
        "\n",
        "lyrics = [normalize_word_line(x) for x in lyrics.splitlines()]\n",
        "lyrics = [x for x in lyrics if x]\n",
        "rhymes = get_rhyme_list(lyrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqrqD4NVfQvP"
      },
      "source": [
        "# 5. Duomenų rinkinio paruošimas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uPtBQstUfj43"
      },
      "outputs": [],
      "source": [
        "def get_rhyme_float(line: list[str], rhyme_list: list[str]) -> float | None:\n",
        "  rhyme = get_rhyme(line)\n",
        "  if rhyme in rhyme_list:\n",
        "    return rhyme_list.index(rhyme) / len(rhyme_list)\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EVXYruyxSRwG"
      },
      "outputs": [],
      "source": [
        "def get_random_lines(markov_model, n_rows: int) -> list[list[str]]:\n",
        "  lines = []\n",
        "  last_words = []\n",
        "\n",
        "  while len(lines) < n_rows:\n",
        "    line = markov_model.make_sentence(max_overlap_ratio = .49, tries = 100)\n",
        "    if (line is not None) and (line not in lines):\n",
        "      last_word = normalize_word_line(line)[-1]\n",
        "      if last_words.count(last_word) < 3:\n",
        "        lines.append(normalize_word_line(line))\n",
        "        last_words.append(last_word)\n",
        "\n",
        "  return lines\n",
        "\n",
        "def get_line_features(line: list[str], rhyme_list: list[str]) -> tuple:\n",
        "  return (line, n_syllables(line), get_rhyme_float(line, rhyme_list))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_lines = get_random_lines(markov_model, 2)\n",
        "# for line in test_lines:\n",
        "#   print(get_line_features(line, rhymes))"
      ],
      "metadata": {
        "id": "cApc_OxSkZ1J",
        "outputId": "a0320a53-76f9-467e-e5e2-7f159230e314",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['but', 'i', 'get', 'to', 'know', 'everything'], 9, 0.2925170068027211)\n",
            "(['not', 'slowing', 'down', \"won't\", 'stop', 'the', 'search', 'for', 'the', 'thrill', 'of', 'it'], 13, 0.8163265306122449)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CxeNDf7afRd1"
      },
      "outputs": [],
      "source": [
        "def build_dataset(lines: list[list[str]], rhyme_list: list[str]):\n",
        "\tfeatures = [get_line_features(x, rhyme_list) for x in lines]\n",
        "\tx_data, y_data = [], []\n",
        "\n",
        "\tfor i in range(len(features) - 3):\n",
        "\t\tline1, line2 = features[i    ][1:], features[i + 1][1:]\n",
        "\t\tline3, line4 = features[i + 2][1:], features[i + 3][1:]\n",
        "\t\tx_data.append(np.array([line1, line2]))\n",
        "\t\ty_data.append(np.array([line3, line4]))\n",
        "\treturn np.array(x_data), np.array(y_data)\n",
        "\n",
        "dataset = build_dataset(lyrics, rhymes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr_2xL_7Woko",
        "outputId": "62414160-2b07-4dd8-87de-4a134421330b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[5.        , 0.17006803],\n",
              "        [7.        , 0.17006803]]),\n",
              " array([[ 5.        ,  0.15646259],\n",
              "        [11.        ,  0.23809524]]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# len(dataset[0]), len(dataset[1])\n",
        "# dataset[0][0], dataset[1][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M65DDnrB1wa9"
      },
      "source": [
        "## 6. RNN modelio inicializavimas\n",
        "\n",
        "Pakeitimas nr.3, LTSM sluoksniai pakeičiami į GRU, pridedami dropout sluokniai ir pakeičiami neuronų kiekiai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "oAMK9WWt11F-",
        "outputId": "ce970554-87ad-44a7-f392-6339a2bda041"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"GRU-based_lyrics_generator\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"GRU-based_lyrics_generator\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m6\u001b[0m)                │             \u001b[38;5;34m180\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m6\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │             \u001b[38;5;34m384\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m)                │              \u001b[38;5;34m72\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │              <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m636\u001b[0m (2.48 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">636</span> (2.48 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m636\u001b[0m (2.48 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">636</span> (2.48 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def create_gru(depth: int):\n",
        "\n",
        "  model = keras.Sequential(name = 'GRU-based_lyrics_generator')\n",
        "  model.add(keras.layers.Input((2, 2)))\n",
        "  model.add(keras.layers.GRU(6, return_sequences = True))\n",
        "  model.add(keras.layers.Dropout(0.3))\n",
        "  for i in range(depth):\n",
        "    model.add(keras.layers.GRU(8, return_sequences = True))\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(keras.layers.GRU(2, return_sequences = True))\n",
        "\n",
        "  model.compile(optimizer = keras.optimizers.RMSprop(learning_rate = 0.001),\n",
        "                loss = 'mse')\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_gru(depth = 1)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HtOIBhYm6Sfr"
      },
      "outputs": [],
      "source": [
        "def compose(starting_input: np.ndarray, rnn_model, n_line_groups: int):\n",
        "\tprev_vectors = starting_input\n",
        "\tfinal_vectors = []\n",
        "\tfor i in range(n_line_groups):\n",
        "\t\tfinal_vectors.append(rnn_model.predict(prev_vectors).flatten().reshape(1, 2, 2))\n",
        "\t\tprev_vectors = final_vectors[-1]\n",
        "\treturn final_vectors\n",
        "\n",
        "\n",
        "def last_word_compare(prev_lines: list[list[str]], new_line: list[str], penalty: float = 0.2) -> float:\n",
        "\tsum_penalty = 0.0\n",
        "\tfor line in prev_lines:\n",
        "\t\tif line[-1] == new_line[-1]:\n",
        "\t\t\tsum_penalty += penalty\n",
        "\treturn sum_penalty\n",
        "\n",
        "\n",
        "def calculate_score(features, n_syllables, rhyme, penalty: float, rhyme_list, maxsyllables):\n",
        "\tdesired_n_syllables = features[0] * maxsyllables\n",
        "\tdesired_rhyme = features[1] * len(rhyme_list)\n",
        "\tsyllable_score = - abs(float(desired_n_syllables) - float(n_syllables))\n",
        "\trhyme_score = abs(float(desired_rhyme) - float(rhyme))\n",
        "\tscore = 1.0 + syllable_score + rhyme_score - penalty\n",
        "\treturn score\n",
        "\n",
        "\n",
        "def vectors_into_song(vectors, generated_lyrics, rhyme_list, maxsyllables: int):\n",
        "\tsong = []\n",
        "\tgenerated_features = [get_line_features(x, rhyme_list) for x in generated_lyrics]\n",
        "\n",
        "\tvector_halves = []\n",
        "\tfor vector in vectors:\n",
        "\t\tvector_halves.extend(vector[0].tolist())\n",
        "\n",
        "\tfor vector in vector_halves:\n",
        "\t\tscorelist = []\n",
        "\n",
        "\t\tfor (line, n_syllables, rhyme) in generated_features:\n",
        "\t\t\tif len(song) != 0:\n",
        "\t\t\t\tpenalty = last_word_compare(song, line)\n",
        "\t\t\telse:\n",
        "\t\t\t\tpenalty = 0\n",
        "\n",
        "\t\t\ttotal_score = calculate_score(vector, n_syllables, rhyme, penalty, rhyme_list, maxsyllables)\n",
        "\t\t\tscorelist.append([line, total_score])\n",
        "\n",
        "\t\tbest_line_index = np.argmax([float(x[1]) for x in scorelist])\n",
        "\t\tbest_line = scorelist[best_line_index][0]\n",
        "\t\tsong.append(best_line)\n",
        "\n",
        "\t\tgenerated_features = [x for x in generated_features if x[0] != best_line]\n",
        "\n",
        "\treturn [' '.join(x) for x in song]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start = np.array([dataset[0][0]])\n",
        "# vectors = compose(start, model, 4)\n",
        "# some_lyrics = get_random_lines(markov_model, 20)\n",
        "# vectors_into_song(vectors, some_lyrics, rhymes, maxsyllables=12)"
      ],
      "metadata": {
        "id": "bqASxqOdE2Tr",
        "outputId": "77294263-bff9-4209-aabe-dc8d55246871",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"don't think for a new day is mine\",\n",
              " \"run run run you're stuck in the grey\",\n",
              " 'and through your eyes and heal the damage',\n",
              " 'i wanna be in your heart of the night',\n",
              " 'oh did you see the fear in your heart speak up',\n",
              " \"but i can't let it go let it dance again\",\n",
              " \"it's reflected in your heart in a second\",\n",
              " 'you were in the shallow we are all we need']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "689lyYJCfLXz"
      },
      "source": [
        "## 7. Modelio apmokymas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsOPxVmxfNsK",
        "outputId": "8381a246-4811-447d-ae95-226217823288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m1989/1989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 28.2541\n",
            "Epoch 2/4\n",
            "\u001b[1m1989/1989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 26.3490\n",
            "Epoch 3/4\n",
            "\u001b[1m1989/1989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 26.3424\n",
            "Epoch 4/4\n",
            "\u001b[1m1989/1989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 26.3411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fbeb18d6ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "x_data, y_data = dataset\n",
        "\n",
        "model.fit(\n",
        "    x_data, y_data,\n",
        "    batch_size = 2,\n",
        "    epochs = 4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Modelio testavimas"
      ],
      "metadata": {
        "id": "7GAipu9kG8oE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLByUoNUgRSQ",
        "outputId": "366b295f-f7f3-429a-b879-b5f8ed1251f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"break through the fire that's the worst plan that you speak of\",\n",
              " 'victoria for you to get it over too soon',\n",
              " 'to keep you safe and hard to be on the beach now',\n",
              " 'but i just wanna look at this world feels so unknown',\n",
              " \"there's no point trying to find something to stand tall\",\n",
              " 'for the ones who will be the one who will rise up',\n",
              " 'i wake up but the time is now or never',\n",
              " 'you thought that i was full of hot air balloons',\n",
              " 'go ahead and try to see the light of your era era',\n",
              " \"see through a mirror feel the pain can't stop thinking about what if\",\n",
              " 'this could be the heat in your view',\n",
              " 'color me and my own path']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "start_i = np.random.choice(range(len(x_data)))\n",
        "start = np.array([x_data[start_i]])\n",
        "vectors = compose(start, model, 6)\n",
        "some_lyrics = get_random_lines(markov_model, 40)\n",
        "vectors_into_song(vectors, some_lyrics, rhymes, maxsyllables = 8)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}